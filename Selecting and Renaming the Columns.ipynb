{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d0d8583-e211-4d67-9d89-67e71d33a0fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1438456753455101>:9\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#02 Creating Spark Data Frame to Select and Rename Columns\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m users \u001B[38;5;241m=\u001B[39m [\n",
       "\u001B[1;32m      4\u001B[0m     {\n",
       "\u001B[1;32m      5\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n",
       "\u001B[1;32m      6\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCorrie\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      7\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVan den Oord\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      8\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcvandenoord0@etsy.com\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[0;32m----> 9\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 234 567 8901\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 234 567 8911\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n",
       "\u001B[1;32m     10\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m],\n",
       "\u001B[1;32m     11\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m     12\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1000.55\u001B[39m,\n",
       "\u001B[1;32m     13\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdate(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m15\u001B[39m),\n",
       "\u001B[1;32m     14\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n",
       "\u001B[1;32m     15\u001B[0m     },\n",
       "\u001B[1;32m     16\u001B[0m     {\n",
       "\u001B[1;32m     17\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m,\n",
       "\u001B[1;32m     18\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNikolaus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     19\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBrewitt\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     20\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbrewitt1@dailymail.co.uk\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     21\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m:  Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 234 567 8923\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1 234 567 8934\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n",
       "\u001B[1;32m     22\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m3\u001B[39m],\n",
       "\u001B[1;32m     23\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m     24\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m900.0\u001B[39m,\n",
       "\u001B[1;32m     25\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdate(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m14\u001B[39m),\n",
       "\u001B[1;32m     26\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m18\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m33\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n",
       "\u001B[1;32m     27\u001B[0m     },\n",
       "\u001B[1;32m     28\u001B[0m     {\n",
       "\u001B[1;32m     29\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m,\n",
       "\u001B[1;32m     30\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOrelie\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     31\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPenney\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     32\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenney2@vistaprint.com\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 714 512 9752\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 714 512 6601\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n",
       "\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m4\u001B[39m],\n",
       "\u001B[1;32m     35\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m     36\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m850.55\u001B[39m,\n",
       "\u001B[1;32m     37\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdate(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m21\u001B[39m),\n",
       "\u001B[1;32m     38\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m55\u001B[39m)\n",
       "\u001B[1;32m     39\u001B[0m     },\n",
       "\u001B[1;32m     40\u001B[0m     {\n",
       "\u001B[1;32m     41\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n",
       "\u001B[1;32m     42\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAshby\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     43\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaddocks\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     44\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamaddocks3@home.pl\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     45\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m),\n",
       "\u001B[1;32m     46\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n",
       "\u001B[1;32m     47\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m     48\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     49\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     50\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m17\u001B[39m, \u001B[38;5;241m45\u001B[39m, \u001B[38;5;241m30\u001B[39m)\n",
       "\u001B[1;32m     51\u001B[0m     },\n",
       "\u001B[1;32m     52\u001B[0m     {\n",
       "\u001B[1;32m     53\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5\u001B[39m,\n",
       "\u001B[1;32m     54\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKurt\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     55\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRome\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     56\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkrome4@shutterfly.com\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     57\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 817 934 7142\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m),\n",
       "\u001B[1;32m     58\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n",
       "\u001B[1;32m     59\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m     60\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     61\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     62\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m55\u001B[39m, \u001B[38;5;241m18\u001B[39m)\n",
       "\u001B[1;32m     63\u001B[0m     }\n",
       "\u001B[1;32m     64\u001B[0m ]\n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
       "\u001B[1;32m     66\u001B[0m spark\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspark.sql.execution.arrow.pyspark.enabled\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'Row' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1438456753455101>:9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#02 Creating Spark Data Frame to Select and Rename Columns\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m\n\u001B[1;32m      3\u001B[0m users \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      4\u001B[0m     {\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCorrie\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVan den Oord\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      8\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcvandenoord0@etsy.com\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 9\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 234 567 8901\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 234 567 8911\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     10\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m],\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1000.55\u001B[39m,\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdate(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m15\u001B[39m),\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     15\u001B[0m     },\n\u001B[1;32m     16\u001B[0m     {\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNikolaus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     19\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBrewitt\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     20\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbrewitt1@dailymail.co.uk\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m:  Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 234 567 8923\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1 234 567 8934\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m3\u001B[39m],\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m900.0\u001B[39m,\n\u001B[1;32m     25\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdate(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m14\u001B[39m),\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m18\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m33\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     27\u001B[0m     },\n\u001B[1;32m     28\u001B[0m     {\n\u001B[1;32m     29\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOrelie\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPenney\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenney2@vistaprint.com\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 714 512 9752\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 714 512 6601\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m4\u001B[39m],\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m850.55\u001B[39m,\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdate(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m21\u001B[39m),\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m55\u001B[39m)\n\u001B[1;32m     39\u001B[0m     },\n\u001B[1;32m     40\u001B[0m     {\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAshby\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMaddocks\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     44\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamaddocks3@home.pl\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m     46\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m     47\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     48\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     49\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m17\u001B[39m, \u001B[38;5;241m45\u001B[39m, \u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m     51\u001B[0m     },\n\u001B[1;32m     52\u001B[0m     {\n\u001B[1;32m     53\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfirst_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKurt\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     55\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRome\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     56\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124memail\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkrome4@shutterfly.com\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     57\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphone_numbers\u001B[39m\u001B[38;5;124m\"\u001B[39m: Row(mobile\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m+1 817 934 7142\u001B[39m\u001B[38;5;124m\"\u001B[39m, home\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcourses\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_customer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     60\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamount_paid\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     61\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcustomer_from\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     62\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlast_updated_ts\u001B[39m\u001B[38;5;124m\"\u001B[39m: datetime\u001B[38;5;241m.\u001B[39mdatetime(\u001B[38;5;241m2021\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m55\u001B[39m, \u001B[38;5;241m18\u001B[39m)\n\u001B[1;32m     63\u001B[0m     }\n\u001B[1;32m     64\u001B[0m ]\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m     66\u001B[0m spark\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspark.sql.execution.arrow.pyspark.enabled\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\n\u001B[0;31mNameError\u001B[0m: name 'Row' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'Row' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#02 Creating Spark Data Frame to Select and Rename Columns\n",
    "import datetime\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": Row(mobile=\"+1 234 567 8901\", home=\"+1 234 567 8911\"),\n",
    "        \"courses\": [1, 2],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\":  Row(mobile=\"+1 234 567 8923\", home=\"1 234 567 8934\"),\n",
    "        \"courses\": [3],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime.date(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": Row(mobile=\"+1 714 512 9752\", home=\"+1 714 512 6601\"),\n",
    "        \"courses\": [2, 4],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": Row(mobile=None, home=None),\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": Row(mobile=\"+1 817 934 7142\", home=None),\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]\n",
    "import pandas as pd\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', False)\n",
    "users_df = spark.createDataFrame(pd.DataFrame(users))\n",
    "users_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb2a2510-09e3-477e-81df-ae25ec7fe72f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#03 Overview of Narrow and Wide Transformations\n",
    "%md \n",
    "\n",
    "\n",
    "Let us get an overview of Narrow and Wide Transformations.\n",
    "* Here are the functions related to narrow transformations. Narrow transformations doesn't result in shuffling. These are also known as row level transformations.\n",
    "  * `df.select`\n",
    "  * `df.filter`\n",
    "  * `df.withColumn`\n",
    "  * `df.withColumnRenamed`\n",
    "  * `df.drop`\n",
    "* Here are the functions related to wide transformations.\n",
    "  * `df.distinct`\n",
    "  * `df.union` or any set operation\n",
    "  * `df.join` or any join operation\n",
    "  * `df.groupBy`\n",
    "  * `df.sort` or `df.orderBy`\n",
    "* Any function that result in shuffling is wide transformation. For all the wide transformations, we have to deal with group of records based on a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd95467d-99ee-4a43-b5bd-1c633b8f91df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#04 Overview of Select on Spark Data Frame\n",
    "%run \"./02 Creating Spark Data Frame to Select and Rename Columns\"\n",
    "help(users_df.select)\n",
    "users_df.select('*').show()\n",
    "users_df.select('id', 'first_name', 'last_name').show()\n",
    "users_df.select(['id', 'first_name', 'last_name']).show()\n",
    "# Defining alias to the dataframe\n",
    "users_df.alias('u').select('u.*').show()\n",
    "users_df.alias('u').select('u.id', 'u.first_name', 'u.last_name').show()\n",
    "from pyspark.sql.functions import col\n",
    "users_df.select(col('id'), 'first_name', 'last_name').show()\n",
    "from pyspark.sql.functions import col, concat, lit\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    'first_name', \n",
    "    'last_name',\n",
    "    concat(col('first_name'), lit(', '), col('last_name')).alias('full_name')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a36d2b73-c4b9-4697-b1de-b258b5c8bd77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method selectExpr in module pyspark.sql.dataframe:\n\nselectExpr(*expr: Union[str, List[str]]) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Projects a set of SQL expressions and returns a new :class:`DataFrame`.\n    \n    This is a variant of :func:`select` that accepts SQL expressions.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Returns\n    -------\n    :class:`DataFrame`\n        A DataFrame with new/old columns transformed by expressions.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([\n    ...     (2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    >>> df.selectExpr(\"age * 2\", \"abs(age)\").show()\n    +---------+--------+\n    |(age * 2)|abs(age)|\n    +---------+--------+\n    |        4|       2|\n    |       10|       5|\n    +---------+--------+\n\n+-----------+-------+-------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n|amount_paid|courses|customer_from|               email|first_name| id|is_customer|   last_name|    last_updated_ts|       phone_numbers|\n+-----------+-------+-------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n|    1000.55| [1, 2]|   2021-01-15|cvandenoord0@etsy...|    Corrie|  1|       true|Van den Oord|2021-02-10 01:15:00|{mobile -> +1 234...|\n|      900.0|    [3]|   2021-02-14|nbrewitt1@dailyma...|  Nikolaus|  2|       true|     Brewitt|2021-02-18 03:33:00|{mobile -> +1 234...|\n|     850.55| [2, 4]|   2021-01-21|openney2@vistapri...|    Orelie|  3|       true|      Penney|2021-03-15 15:16:55|{mobile -> +1 714...|\n|       null|     []|         null|  amaddocks3@home.pl|     Ashby|  4|      false|    Maddocks|2021-04-10 17:45:30|{mobile -> null, ...|\n|       null|     []|         null|krome4@shutterfly...|      Kurt|  5|      false|        Rome|2021-04-02 00:55:18|{mobile -> +1 817...|\n+-----------+-------+-------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n\n+-----------+-------+-------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n|amount_paid|courses|customer_from|               email|first_name| id|is_customer|   last_name|    last_updated_ts|       phone_numbers|\n+-----------+-------+-------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n|    1000.55| [1, 2]|   2021-01-15|cvandenoord0@etsy...|    Corrie|  1|       true|Van den Oord|2021-02-10 01:15:00|{mobile -> +1 234...|\n|      900.0|    [3]|   2021-02-14|nbrewitt1@dailyma...|  Nikolaus|  2|       true|     Brewitt|2021-02-18 03:33:00|{mobile -> +1 234...|\n|     850.55| [2, 4]|   2021-01-21|openney2@vistapri...|    Orelie|  3|       true|      Penney|2021-03-15 15:16:55|{mobile -> +1 714...|\n|       null|     []|         null|  amaddocks3@home.pl|     Ashby|  4|      false|    Maddocks|2021-04-10 17:45:30|{mobile -> null, ...|\n|       null|     []|         null|krome4@shutterfly...|      Kurt|  5|      false|        Rome|2021-04-02 00:55:18|{mobile -> +1 817...|\n+-----------+-------+-------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n\n+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\n+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#05 Overview of selectExpr on Spark Data Frame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat, lit, col\n",
    "import datetime\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8901\", \"home\": \"+1 234 567 8911\"},\n",
    "        \"courses\": [1, 2],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\":  {\"mobile\": \"+1 234 567 8923\", \"home\": \"1 234 567 8934\"},\n",
    "        \"courses\": [3],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime.date(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 714 512 9752\", \"home\": \"+1 714 512 6601\"},\n",
    "        \"courses\": [2, 4],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": {\"mobile\": None, \"home\": None},\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 817 934 7142\", \"home\": None},\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Now, perform the operations\n",
    "help(users_df.selectExpr)\n",
    "users_df.selectExpr('*').show()\n",
    "\n",
    "# Defining alias to the dataframe\n",
    "users_df_alias = users_df.alias('u')\n",
    "users_df_alias.selectExpr('u.*').show()\n",
    "\n",
    "users_df.selectExpr('id', 'first_name', 'last_name').show()\n",
    "\n",
    "users_df.selectExpr(['id', 'first_name', 'last_name']).show()\n",
    "\n",
    "users_df. \\\n",
    "    select(\n",
    "        'id', 'first_name', 'last_name', \n",
    "        concat(col('first_name'), lit(', '), col('last_name')).alias('full_name')\n",
    "    ). \\\n",
    "    show()\n",
    "\n",
    "users_df.selectExpr('id', 'first_name', 'last_name', \"concat(first_name, ', ', last_name) AS full_name\").show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT id, first_name, last_name,\n",
    "        concat(first_name, ', ', last_name) AS full_name\n",
    "    FROM users\n",
    "\"\"\"). \\\n",
    "    show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "818eae5c-229a-47db-803a-d6a2b2f03306",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n|amount_paid|courses|      customer_from|               email|first_name| id|is_customer|   last_name|    last_updated_ts|       phone_numbers|\n+-----------+-------+-------------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n|    1000.55| [1, 2]|2021-01-15 00:00:00|cvandenoord0@etsy...|    Corrie|  1|       true|Van den Oord|2021-02-10 01:15:00|{mobile -> +1 234...|\n|      900.0|    [3]|2021-02-14 00:00:00|nbrewitt1@dailyma...|  Nikolaus|  2|       true|     Brewitt|2021-02-18 03:33:00|{mobile -> +1 234...|\n|     850.55| [2, 4]|2021-01-21 00:00:00|openney2@vistapri...|    Orelie|  3|       true|      Penney|2021-03-15 15:16:55|{mobile -> +1 714...|\n|       null|     []|               null|  amaddocks3@home.pl|     Ashby|  4|      false|    Maddocks|2021-04-10 17:45:30|{mobile -> null, ...|\n|       null|     []|               null|krome4@shutterfly...|      Kurt|  5|      false|        Rome|2021-04-02 00:55:18|{mobile -> +1 817...|\n+-----------+-------+-------------------+--------------------+----------+---+-----------+------------+-------------------+--------------------+\n\n+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#06 Referring Columns using Spark Data Frame Names\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat, lit, col\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# User data\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8901\", \"home\": \"+1 234 567 8911\"},\n",
    "        \"courses\": [1, 2],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8923\", \"home\": \"1 234 567 8934\"},\n",
    "        \"courses\": [3],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 714 512 9752\", \"home\": \"+1 714 512 6601\"},\n",
    "        \"courses\": [2, 4],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": {\"mobile\": None, \"home\": None},\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 817 934 7142\", \"home\": None},\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Show all columns\n",
    "users_df.show()\n",
    "\n",
    "# Select specific columns using selectExpr\n",
    "users_df.selectExpr('id', 'first_name', 'last_name').show()\n",
    "\n",
    "# Concatenate first_name and last_name to create full_name column\n",
    "users_df.select(\n",
    "    'id', 'first_name', 'last_name', \n",
    "    concat(col('first_name'), lit(', '), col('last_name')).alias('full_name')\n",
    ").show()\n",
    "\n",
    "# Using selectExpr to create full_name\n",
    "users_df.selectExpr('id', 'first_name', 'last_name', \"concat(first_name, ', ', last_name) AS full_name\").show()\n",
    "\n",
    "# Creating a temporary view\n",
    "users_df.createOrReplaceTempView('users')\n",
    "\n",
    "# Running SQL query on the temporary view\n",
    "spark.sql(\"\"\"\n",
    "    SELECT id, first_name, last_name,\n",
    "        concat(first_name, ', ', last_name) AS full_name\n",
    "    FROM users\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffbc1097-a9d6-47df-8834-92f593a6b5a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\n+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\nHelp on function col in module pyspark.sql.functions:\n\ncol(col: str) -> pyspark.sql.column.Column\n    Returns a :class:`~pyspark.sql.Column` based on the given column name.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    col : str\n        the name for the column\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        the corresponding column instance.\n    \n    Examples\n    --------\n    >>> col('x')\n    Column<'x'>\n    >>> column('x')\n    Column<'x'>\n\n+---+\n| id|\n+---+\n|  1|\n|  2|\n|  3|\n|  4|\n|  5|\n+---+\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|   2021-01-15|\n|  2|   2021-02-14|\n|  3|   2021-01-21|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n+---+------------------------------------+\n| id|date_format(customer_from, yyyyMMdd)|\n+---+------------------------------------+\n|  1|                            20210115|\n|  2|                            20210214|\n|  3|                            20210121|\n|  4|                                null|\n|  5|                                null|\n+---+------------------------------------+\n\nroot\n |-- id: long (nullable = true)\n |-- date_format(customer_from, yyyyMMdd): string (nullable = true)\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|     20210115|\n|  2|     20210214|\n|  3|     20210121|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|     20210115|\n|  2|     20210214|\n|  3|     20210121|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\nroot\n |-- id: long (nullable = true)\n |-- customer_from: integer (nullable = true)\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|     20210115|\n|  2|     20210214|\n|  3|     20210121|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format\n",
    "import datetime\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8901\", \"home\": \"+1 234 567 8911\"},\n",
    "        \"courses\": [1, 2],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\":  {\"mobile\": \"+1 234 567 8923\", \"home\": \"1 234 567 8934\"},\n",
    "        \"courses\": [3],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime.date(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 714 512 9752\", \"home\": \"+1 714 512 6601\"},\n",
    "        \"courses\": [2, 4],\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": {\"mobile\": None, \"home\": None},\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 817 934 7142\", \"home\": None},\n",
    "        \"courses\": [],\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Perform the operations\n",
    "users_df['id']\n",
    "col('id')\n",
    "users_df.select('id', 'first_name', 'last_name').show()\n",
    "cols = ['id', 'first_name', 'last_name']\n",
    "users_df.select(*cols).show()\n",
    "help(col)\n",
    "user_id = col('id')\n",
    "user_id\n",
    "users_df.select(user_id).show()\n",
    "users_df.select('id', 'customer_from').show()\n",
    "users_df.select('id', 'customer_from').dtypes\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd')\n",
    ").show()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd')\n",
    ").printSchema()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd').alias('customer_from')\n",
    ").show()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')\n",
    ").show()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')\n",
    ").printSchema()\n",
    "\n",
    "cols = [col('id'), date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')]\n",
    "users_df.select(*cols).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563dc9ea-6ed6-484c-a8ea-476183099fc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\n+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\nHelp on function col in module pyspark.sql.functions:\n\ncol(col: str) -> pyspark.sql.column.Column\n    Returns a :class:`~pyspark.sql.Column` based on the given column name.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    col : str\n        the name for the column\n    \n    Returns\n    -------\n    :class:`~pyspark.sql.Column`\n        the corresponding column instance.\n    \n    Examples\n    --------\n    >>> col('x')\n    Column<'x'>\n    >>> column('x')\n    Column<'x'>\n\n+---+\n| id|\n+---+\n|  1|\n|  2|\n|  3|\n|  4|\n|  5|\n+---+\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|   2021-01-15|\n|  2|   2021-02-14|\n|  3|   2021-01-21|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n+---+------------------------------------+\n| id|date_format(customer_from, yyyyMMdd)|\n+---+------------------------------------+\n|  1|                            20210115|\n|  2|                            20210214|\n|  3|                            20210121|\n|  4|                                null|\n|  5|                                null|\n+---+------------------------------------+\n\nroot\n |-- id: long (nullable = true)\n |-- date_format(customer_from, yyyyMMdd): string (nullable = true)\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|     20210115|\n|  2|     20210214|\n|  3|     20210121|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|     20210115|\n|  2|     20210214|\n|  3|     20210121|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\nroot\n |-- id: long (nullable = true)\n |-- customer_from: integer (nullable = true)\n\n+---+-------------+\n| id|customer_from|\n+---+-------------+\n|  1|     20210115|\n|  2|     20210214|\n|  3|     20210121|\n|  4|         null|\n|  5|         null|\n+---+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "#08 Invoking Functions using Spark Column Objects\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, date_format\n",
    "import datetime\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8901\", \"home\": \"+1 234 567 8911\"},\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\":  {\"mobile\": \"+1 234 567 8923\", \"home\": \"1 234 567 8934\"},\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 900.0,\n",
    "        \"customer_from\": datetime.date(2021, 2, 14),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 18, 3, 33, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 714 512 9752\", \"home\": \"+1 714 512 6601\"},\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 850.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 21),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 3, 15, 15, 16, 55)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": {\"mobile\": None, \"home\": None},\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 10, 17, 45, 30)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 817 934 7142\", \"home\": None},\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 4, 2, 0, 55, 18)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Perform the operations\n",
    "users_df['id']\n",
    "col('id')\n",
    "users_df.select('id', 'first_name', 'last_name').show()\n",
    "cols = ['id', 'first_name', 'last_name']\n",
    "users_df.select(*cols).show()\n",
    "help(col)\n",
    "user_id = col('id')\n",
    "user_id\n",
    "users_df.select(user_id).show()\n",
    "users_df.select('id', 'customer_from').show()\n",
    "users_df.select('id', 'customer_from').dtypes\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd')\n",
    ").show()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd')\n",
    ").printSchema()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd').alias('customer_from')\n",
    ").show()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')\n",
    ").show()\n",
    "users_df.select(\n",
    "    col('id'), \n",
    "    date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')\n",
    ").printSchema()\n",
    "\n",
    "cols = [col('id'), date_format('customer_from', 'yyyyMMdd').cast('int').alias('customer_from')]\n",
    "users_df.select(*cols).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa242c43-817a-4a6e-967f-308956343cf6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n| id|amount_paid|\n+---+-----------+\n|  1|    1025.55|\n|  2|      925.0|\n|  3|     875.55|\n|  4|       null|\n|  5|       null|\n+---+-----------+\n\n+---+-----------+\n| id|amount_paid|\n+---+-----------+\n|  1|    1025.55|\n|  2|      925.0|\n|  3|     875.55|\n|  4|       null|\n|  5|       null|\n+---+-----------+\n\nColumn<'25'>\nColumn<'(25.0 + amount_paid)'>\nColumn<'(25.0 + amount_paid)'>\n+---+--------------------+---------+\n| id|(25.0 + amount_paid)|(50 + 25)|\n+---+--------------------+---------+\n|  1|                null|       75|\n|  2|                null|       75|\n|  3|                null|       75|\n|  4|                null|       75|\n|  5|                null|       75|\n+---+--------------------+---------+\n\n+---+--------------------+\n| id|(amount_paid + 25.0)|\n+---+--------------------+\n|  1|             1025.55|\n|  2|               925.0|\n|  3|              875.55|\n|  4|                null|\n|  5|                null|\n+---+--------------------+\n\nColumn<'25.0'>\n"
     ]
    }
   ],
   "source": [
    "#09 Understanding lit function in Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, col\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"amount_paid\": 1000.55\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"amount_paid\": 900.0\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"amount_paid\": 850.55\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"amount_paid\": None\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"amount_paid\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Create temporary view\n",
    "users_df.createOrReplaceTempView('users')\n",
    "\n",
    "# Perform the operations\n",
    "spark.sql(\"\"\"\n",
    "    SELECT id, (amount_paid + 25) AS amount_paid\n",
    "    FROM users\n",
    "\"\"\").show()\n",
    "\n",
    "users_df.selectExpr('id', '(amount_paid + 25) AS amount_paid').show()\n",
    "\n",
    "# This will fail\n",
    "# users_df.select('id', 'amount_paid' + 25).show()  # Uncommenting this line will cause an error\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "print(lit(25))  # Show the result of lit(25)\n",
    "\n",
    "# This will also fail\n",
    "# users_df.select('id', 'amount_paid' + '25').show()  # Uncommenting this line will cause an error\n",
    "\n",
    "from pyspark.sql.functions import lit, col\n",
    "\n",
    "print('amount_paid' + lit(25.0))  # Show the result of 'amount_paid' + lit(25.0)\n",
    "print('amount_paid' + lit('25.0'))  # Show the result of 'amount_paid' + lit('25.0')\n",
    "\n",
    "# Returns null\n",
    "# amount_paid is converted to string by implicitly using lit.\n",
    "# Spark returns null when we perform arithmetic operations on noncompatible types\n",
    "users_df.select('id', 'amount_paid' + lit(25.0), lit(50) + lit(25)).show()\n",
    "\n",
    "# This works\n",
    "users_df.select('id', col('amount_paid') + lit(25.0)).show()\n",
    "\n",
    "# lit returns column type\n",
    "print(lit(25.0))  # Show the result of lit(25.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4584187-d1e8-4afc-8944-974f78479fbf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#10 Overview of Renaming Spark Data Frame Columns or Expressions\n",
    "There are multiple ways to rename Spark Data Frame Columns or Expressions.\n",
    "* We can rename column or expression using `alias` as part of `select`\n",
    "* We can add or rename column or expression using `withColumn` on top of Data Frame.\n",
    "* We can rename one column at a time using `withColumnRenamed` on top of Data Frame.\n",
    "* We typically use `withColumn` to perform row level transformations and then to provide a name to the result. If we provide the same name as existing column, then the column will be replaced with new one.\n",
    "* If we want to just rename the column then it is better to use `withColumnRenamed`.\n",
    "* If we want to apply any transformation, we need to either use `select` or `withColumn`\n",
    "* We can rename bunch of columns using `toDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d6c8e1-1edf-49b8-8713-355966fd1a5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n| id|first_name|   last_name|\n+---+----------+------------+\n|  1|    Corrie|Van den Oord|\n|  2|  Nikolaus|     Brewitt|\n|  3|    Orelie|      Penney|\n|  4|     Ashby|    Maddocks|\n|  5|      Kurt|        Rome|\n+---+----------+------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\n+---+----------+------------+--------------------+\n| id|first_name|   last_name|           full_name|\n+---+----------+------------+--------------------+\n|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n|  3|    Orelie|      Penney|      Orelie, Penney|\n|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n|  5|      Kurt|        Rome|          Kurt, Rome|\n+---+----------+------------+--------------------+\n\nHelp on method withColumn in module pyspark.sql.dataframe:\n\nwithColumn(colName: str, col: pyspark.sql.column.Column) -> 'DataFrame' method of pyspark.sql.dataframe.DataFrame instance\n    Returns a new :class:`DataFrame` by adding a column or replacing the\n    existing column that has the same name.\n    \n    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n    a column from some other :class:`DataFrame` will raise an error.\n    \n    .. versionadded:: 1.3.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    colName : str\n        string, name of the new column.\n    col : :class:`Column`\n        a :class:`Column` expression for the new column.\n    \n    Returns\n    -------\n    :class:`DataFrame`\n        DataFrame with new or replaced column.\n    \n    Notes\n    -----\n    This method introduces a projection internally. Therefore, calling it multiple\n    times, for instance, via loops in order to add multiple columns can generate big\n    plans which can cause performance issues and even `StackOverflowException`.\n    To avoid this, use :func:`select` with multiple columns at once.\n    \n    Examples\n    --------\n    >>> df = spark.createDataFrame([(2, \"Alice\"), (5, \"Bob\")], schema=[\"age\", \"name\"])\n    >>> df.withColumn('age2', df.age + 2).show()\n    +---+-----+----+\n    |age| name|age2|\n    +---+-----+----+\n    |  2|Alice|   4|\n    |  5|  Bob|   7|\n    +---+-----+----+\n\n+---+----------+------------+--------+\n| id|first_name|   last_name|      fn|\n+---+----------+------------+--------+\n|  1|    Corrie|Van den Oord|  Corrie|\n|  2|  Nikolaus|     Brewitt|Nikolaus|\n|  3|    Orelie|      Penney|  Orelie|\n|  4|     Ashby|    Maddocks|   Ashby|\n|  5|      Kurt|        Rome|    Kurt|\n+---+----------+------------+--------+\n\n+---+-------+\n| id|courses|\n+---+-------+\n|  1| [1, 2]|\n|  2|    [3]|\n|  3| [2, 4]|\n|  4|     []|\n|  5|     []|\n+---+-------+\n\n+---+-------+------------+\n| id|courses|course_count|\n+---+-------+------------+\n|  1| [1, 2]|           2|\n|  2|    [3]|           1|\n|  3| [2, 4]|           2|\n|  4|     []|           0|\n|  5|     []|           0|\n+---+-------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#11 Naming derived columns using withColumn\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat, lit, col, size\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"courses\": [1, 2]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"courses\": [3]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"courses\": [2, 4]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"courses\": []\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"courses\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Display 'id', 'first_name', 'last_name'\n",
    "users_df.select('id', 'first_name', 'last_name').show()\n",
    "\n",
    "# Equivalent logic using select\n",
    "users_df.select(\n",
    "    'id', 'first_name', 'last_name',\n",
    "    concat('first_name', lit(', '), 'last_name').alias('full_name')\n",
    ").show()\n",
    "\n",
    "# Equivalent logic using withColumn\n",
    "users_df.select('id', 'first_name', 'last_name').withColumn('full_name', concat('first_name', lit(', '), 'last_name')).show()\n",
    "\n",
    "# Help for withColumn function\n",
    "help(users_df.withColumn)\n",
    "\n",
    "# Add a new column 'fn' with the same values as 'first_name'\n",
    "users_df.select('id', 'first_name', 'last_name').withColumn('fn', users_df['first_name']).show()\n",
    "\n",
    "# Display 'id' and 'courses' columns\n",
    "users_df.select('id', 'courses').show()\n",
    "\n",
    "# Display data types of 'id' and 'courses' columns\n",
    "users_df.select('id', 'courses').dtypes\n",
    "\n",
    "# Add a new column 'course_count' containing the size of the 'courses' array\n",
    "users_df.select('id', 'courses').withColumn('course_count', size('courses')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f38fde85-505e-4668-85c4-af869646a07f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#12 Renaming Columns using withColumnRenamed\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Display the original DataFrame\n",
    "users_df.select('id', 'first_name', 'last_name').show()\n",
    "\n",
    "# Rename columns 'id', 'first_name', and 'last_name'\n",
    "renamed_df = users_df.select('id', 'first_name', 'last_name') \\\n",
    "    .withColumnRenamed('id', 'user_id') \\\n",
    "    .withColumnRenamed('first_name', 'user_first_name') \\\n",
    "    .withColumnRenamed('last_name', 'user_last_name')\n",
    "\n",
    "# Show the DataFrame with renamed columns\n",
    "renamed_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "727392cd-ba91-4c52-a318-23e5705c326a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#13 Renaming Spark Data Frame columns or expressions using alias\n",
    "from pyspark.sql.functions import col, concat, lit\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Display help for alias function\n",
    "help(col('id').alias)\n",
    "\n",
    "# Using select\n",
    "users_df.select(\n",
    "    col('id').alias('user_id'),\n",
    "    col('first_name').alias('user_first_name'),\n",
    "    col('last_name').alias('user_last_name'),\n",
    "    concat(col('first_name'), lit(', '), col('last_name')).alias('user_full_name')\n",
    ").show()\n",
    "\n",
    "# Using withColumn and alias (first select and then withColumn)\n",
    "users_df.select(\n",
    "    col('id').alias('user_id'),\n",
    "    col('first_name').alias('user_first_name'),\n",
    "    col('last_name').alias('user_last_name')\n",
    ").withColumn('user_full_name', concat(col('user_first_name'), lit(', '), col('user_last_name'))).show()\n",
    "\n",
    "# Using withColumn and alias (first withColumn and then select)\n",
    "users_df.withColumn('user_full_name', concat(col('first_name'), lit(', '), col('last_name'))) \\\n",
    "    .select(\n",
    "        col('id').alias('user_id'),\n",
    "        col('first_name').alias('user_first_name'),\n",
    "        col('last_name').alias('user_last_name'),\n",
    "        'user_full_name'\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "993034ba-c055-40b8-9b6d-746148ea0b90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#14 Renaming and Reordering multiple Spark Data Frame Columns\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the dataset\n",
    "users = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoord0@etsy.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8901\", \"home\": \"+1 234 567 8911\"},\n",
    "        \"courses\": [1, 2]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"Nikolaus\",\n",
    "        \"last_name\": \"Brewitt\",\n",
    "        \"email\": \"nbrewitt1@dailymail.co.uk\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 234 567 8923\", \"home\": \"+1 234 567 8934\"},\n",
    "        \"courses\": [3]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Orelie\",\n",
    "        \"last_name\": \"Penney\",\n",
    "        \"email\": \"openney2@vistaprint.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 714 512 9752\", \"home\": \"+1 714 512 6601\"},\n",
    "        \"courses\": [2, 4]\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Ashby\",\n",
    "        \"last_name\": \"Maddocks\",\n",
    "        \"email\": \"amaddocks3@home.pl\",\n",
    "        \"phone_numbers\": None,\n",
    "        \"courses\": []\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Kurt\",\n",
    "        \"last_name\": \"Rome\",\n",
    "        \"email\": \"krome4@shutterfly.com\",\n",
    "        \"phone_numbers\": {\"mobile\": \"+1 817 934 7142\"},\n",
    "        \"courses\": []\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "users_df = spark.createDataFrame(users)\n",
    "\n",
    "# Define required and target columns\n",
    "required_columns = ['id', 'first_name', 'last_name', 'email', 'phone_numbers', 'courses']\n",
    "target_column_names = ['user_id', 'user_first_name', 'user_last_name', 'user_email', 'user_phone_numbers', 'enrolled_courses']\n",
    "\n",
    "# Display help for toDF function\n",
    "help(users_df.toDF)\n",
    "\n",
    "# Select and display required columns\n",
    "users_df.select(required_columns).show()\n",
    "\n",
    "# Select required columns and rename them\n",
    "renamed_df = users_df.select(required_columns).toDF(*target_column_names)\n",
    "\n",
    "# Show the DataFrame with renamed columns\n",
    "renamed_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Selecting and Renaming the Columns",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
